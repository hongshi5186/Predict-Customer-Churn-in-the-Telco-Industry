---
title: "Advance Stats I Project: Predic Customer Churn in the Telco Industry"
author: "Luke Philip Ogweno and Hong Shi"
format: pdf
editor: visual
---

# Exploration and Data Analysis (EDA)

## Load libraries

```{r, message = FALSE, warning = FALSE}
library(plyr)
library(corrplot)
library(ggplot2)
library(gridExtra)
library(ggthemes)
library(caret)
library(MASS)
library(randomForest)
library(party)
library(Amelia)
library(mlbench)
library(rpart)  
library(rpart.plot) 

```

**The data was downloaded from [IBM Sample Data Sets](https://www.ibm.com/communities/analytics/watson-analytics-blog/guide-to-sample-datasets/). Each row represents a customer, each column contains that customer's attributes:**

```{r}
#churn <- read.csv('https://raw.githubusercontent.com/microbhai/CustomerChurnAnalysis/master/telecommunication_customer_churn.csv')

churn <- read.csv('https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv')
str(churn)
```

The raw data contains 7043 rows (customers) and 21 columns (features). The "Churn" column is our target. We used all other columns as features to our model.

## **Missing values in each columns**

We use sapply to check the number if missing values in each columns. We found that there are 11 missing values in "TotalCharges" columns. So, let's remove all rows with missing values.

```{r}
sapply(churn, function(x) sum(is.na(x)))
```

```{r}
churn <- churn[complete.cases(churn), ]
```

Check missingness in the variables

```{r}
missmap(churn, col=c("blue", "red"), legend=FALSE)
```

No missing data in this dataset!

## **Data wrangling**

**Look at the variables, we can see that we have some wranglings to do.**

### **1. We will change "No internet service" to "No" for six columns, they are: "OnlineSecurity", "OnlineBackup", "DeviceProtection", "TechSupport", "streamingTV", "streamingMovies".**

```{r}
cols_recode1 <- c(10:15)
for(i in 1:ncol(churn[,cols_recode1])) {
        churn[,cols_recode1][,i] <- as.factor(mapvalues
                                              (churn[,cols_recode1][,i], from =c("No internet service"),to=c("No")))
}
```

### **2. Change "No phone service" to "No" for column "MultipleLines"**

```{r}
churn$MultipleLines <- as.factor(mapvalues(churn$MultipleLines, 
                                           from=c("No phone service"),
                                           to=c("No")))
```

### **3. Grouping Tenure**

Since the minimum tenure is 1 month and maximum tenure is 72 months, we can group them into five tenure groups: "0--12 Month", "12--24 Month", "24--48 Months", "48--60 Month", "\> 60 Month"

```{r}
min(churn$tenure); max(churn$tenure)
```

Grouping as shown below

```{r}
group_tenure <- function(tenure){
    if (tenure >= 0 & tenure <= 12){
        return('0-12 Month')
    }else if(tenure > 12 & tenure <= 24){
        return('12-24 Month')
    }else if (tenure > 24 & tenure <= 48){
        return('24-48 Month')
    }else if (tenure > 48 & tenure <=60){
        return('48-60 Month')
    }else if (tenure > 60){
        return('> 60 Month')
    }
}
```

```{r}
churn$tenure_group <- sapply(churn$tenure,group_tenure)
churn$tenure_group <- as.factor(churn$tenure_group)
```

### **4. Change the values in column "SeniorCitizen" from 0 or 1 to "No" or "Yes".**

```{r}
churn$SeniorCitizen <- as.factor(mapvalues(churn$SeniorCitizen,
                                      from=c("0","1"),
                                      to=c("No", "Yes")))
```

```{r}
churn$Churn <- as.factor(mapvalues(churn$Churn,
                                      from=c("No","Yes"),
                                      to=c("0", "1")))
```

### **5. Remove the columns we do not need for the analysis.**

```{r}
churn$customerID <- NULL
churn$tenure <- NULL
```

## **Exploratory data analysis and feature selection**

### **Correlation between numeric variables**

```{r}
numeric.var <- sapply(churn, is.numeric)
corr.matrix <- cor(churn[,numeric.var])
corrplot(corr.matrix, main="\n\nCorrelation Plot for Numerical Variables", method="number")
```

The Monthly Charges and Total Charges are correlated. So one of them will be removed from the model. We remove Total Charges.

Remove TotalCharges

```{r}
churn$TotalCharges <- NULL
```

### **Bar plots of categorical variables**

```{r}
p1 <- ggplot(churn, aes(x=gender)) + ggtitle("Gender") + xlab("Gender") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p2 <- ggplot(churn, aes(x=SeniorCitizen)) + ggtitle("Senior Citizen") + xlab("Senior Citizen") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p3 <- ggplot(churn, aes(x=Partner)) + ggtitle("Partner") + xlab("Partner") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p4 <- ggplot(churn, aes(x=Dependents)) + ggtitle("Dependents") + xlab("Dependents") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
grid.arrange(p1, p2, p3, p4, ncol=2)
```

```{r}
p5 <- ggplot(churn, aes(x=PhoneService)) + ggtitle("Phone Service") + xlab("Phone Service") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p6 <- ggplot(churn, aes(x=MultipleLines)) + ggtitle("Multiple Lines") + xlab("Multiple Lines") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p7 <- ggplot(churn, aes(x=InternetService)) + ggtitle("Internet Service") + xlab("Internet Service") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p8 <- ggplot(churn, aes(x=OnlineSecurity)) + ggtitle("Online Security") + xlab("Online Security") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
grid.arrange(p5, p6, p7, p8, ncol=2)
```

```{r}
p9 <- ggplot(churn, aes(x=OnlineBackup)) + ggtitle("Online Backup") + xlab("Online Backup") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p10 <- ggplot(churn, aes(x=DeviceProtection)) + ggtitle("Device Protection") + xlab("Device Protection") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p11 <- ggplot(churn, aes(x=TechSupport)) + ggtitle("Tech Support") + xlab("Tech Support") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p12 <- ggplot(churn, aes(x=StreamingTV)) + ggtitle("Streaming TV") + xlab("Streaming TV") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
grid.arrange(p9, p10, p11, p12, ncol=2)
```

```{r}
p13 <- ggplot(churn, aes(x=StreamingMovies)) + ggtitle("Streaming Movies") + xlab("Streaming Movies") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p14 <- ggplot(churn, aes(x=Contract)) + ggtitle("Contract") + xlab("Contract") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p15 <- ggplot(churn, aes(x=PaperlessBilling)) + ggtitle("Paperless Billing") + xlab("Paperless Billing") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p16 <- ggplot(churn, aes(x=PaymentMethod)) + ggtitle("Payment Method") + xlab("Payment Method") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p17 <- ggplot(churn, aes(x=tenure_group)) + ggtitle("Tenure Group") + xlab("Tenure Group") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
grid.arrange(p13, p14, p15, p16, p17, ncol=2)
```

All of the categorical variables seem to have a reasonably broad distribution, therefore, all of them will be kept for the further analysis.

## **Logistic Regression**

First, we split the data into training and testing sets

```{r}
intrain<- createDataPartition(churn$Churn,p=0.7,list=FALSE)
set.seed(2022)
training<- churn[intrain,]
testing<- churn[-intrain,]
```

Check out the results if correct

```{r}
dim(training); dim(testing)
```

### **Fitting the Logistic Regression Model**

```{r}
LogModel <- glm(Churn ~., data=training,family=binomial(link="logit"))
print(summary(LogModel))
```

## **Feature Analysis**

The top three most-relevant features include Contract, tenure_group and PaperlessBilling.

```{r}
anova(LogModel, test="Chisq")
```

Analyzing the deviance table we can see the drop in deviance when adding each variable one at a time. Adding InternetService, Contract and tenure_group significantly reduces the residual deviance. The other variables such as PaymentMethod and Dependents seem to improve the model less even though they all have low p-values.

## **Assessing the predictive ability of the Logistic Regression model**

```{r}
testing$Churn <- as.character(testing$Churn)
testing$Churn[testing$Churn=="No"] <- "0"
testing$Churn[testing$Churn=="Yes"] <- "1"
fitted.results <- predict(LogModel,newdata=testing,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != testing$Churn)
print(paste('Logistic Regression Accuracy',1-misClasificError))
```

### **Logistic Regression Confusion Matrix**

```{r}
print("Confusion Matrix for Logistic Regression"); table(testing$Churn, fitted.results > 0.5)
```

### **Odds Ratio**

**\
**One of the interesting performance measurements in logistic regression is Odds Ratio.Basically, Odds ratio is what the odds of an event is happening.

```{r}
exp(cbind(OR=coef(LogModel), confint(LogModel)))
```

For each unit increase in Monthly Charge, there is a 2.4% decrease in the likelihood of a customer's churning.

## **Decision Tree**

### **Decision Tree visualization**

```{r}
# rm(list = ls(all.names = TRUE))
# gc() #free up memrory and report the memory usage.
```

Clear the console

```{r}
# cls <- function() {
# if (.Platform$GUI[1] != "Rgui")
# return(invisible(FALSE))
# if (!require(rcom, quietly = TRUE)) # Not shown any way!
# stop("Package rcom is required for 'cls()'")
# wsh <- comCreateObject("Wscript.Shell")
# if (is.null(wsh)) {
#     return(invisible(FALSE))
# } else {
# comInvoke(wsh, "SendKeys", "\014")
#     return(invisible(TRUE))
# }
# }
# cls()
```

**\
**For illustration purpose, we are going to use only three variables for plotting Decision Trees, they are "Contract", "tenure_group" and "PaperlessBilling".

```{r}
churn <- read.csv('https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv', stringsAsFactors=T)
churn <- churn[complete.cases(churn), ]
```

```{r}
cols_recode1 <- c(10:15)
for(i in 1:ncol(churn[,cols_recode1])) {
        churn[,cols_recode1][,i] <- as.factor(mapvalues
                                              (churn[,cols_recode1][,i], from =c("No internet service"),to=c("No")))
}
```

Grouping

```{r}
group_tenure <- function(tenure){
    if (tenure >= 0 & tenure <= 12){
        return('0-12 Month')
    }else if(tenure > 12 & tenure <= 24){
        return('12-24 Month')
    }else if (tenure > 24 & tenure <= 48){
        return('24-48 Month')
    }else if (tenure > 48 & tenure <=60){
        return('48-60 Month')
    }else if (tenure > 60){
        return('> 60 Month')
    }
}
```

```{r}
churn$tenure_group <- sapply(churn$tenure,group_tenure)
churn$tenure_group <- as.factor(churn$tenure_group)
```

```{r}
churn$SeniorCitizen <- as.factor(mapvalues(churn$SeniorCitizen,
                                      from=c("0","1"),
                                      to=c("No", "Yes")))
```

```{r}
churn$customerID <- NULL
churn$tenure <- NULL
churn$TotalCharges <- NULL
```

```{r}
intrain<- createDataPartition(churn$Churn,p=0.7,list=FALSE)
set.seed(2017)
training<- churn[intrain,]
testing<- churn[-intrain,]
```

For illustration purpose, we are going to use only three variables, they are "Contract", "tenure_group" and "PaperlessBilling".

```{r}
tree <- ctree(Churn~Contract+tenure_group+PaperlessBilling, training)
```

```{r}
plot(tree, type='simple')
```

```{r}
# tree <- rpart(Churn~Contract+tenure_group+PaperlessBilling, training, method = "class") #assigns decision tree values
```

`{# {r} # library(rpart) # library(rpart.plot)  # rpart.plot(tree, tweak = 1.8)     #generate the decision tree # rpart.plot(tree, type = 4, extra = 101, tweak = 1.8) #generate decision tree with more descriptions # fancyRpartPlot(tree)`

1\. Out of three variables we use, Contract is the most important variable to predict customer churn or not churn.\
2. If a customer in a one-year or two-year contract, no matter he (she) has PapelessBilling or not, he (she) is less likely to churn.\
3. On the other hand, if a customer is in a month-to-month contract, and in the tenure group of 0--12 month, and using PaperlessBilling, then this customer is more likely to churn.

### **Decision Tree Confusion Matrix**

**\
**We are using all the variables to product confusion matrix table and make predictions.

```{r}
pred_tree <- predict(tree, testing)
print("Confusion Matrix for Decision Tree"); table(Predicted = pred_tree, Actual = testing$Churn)
```

### **Decision Tree Accuracy**

```{r}
p1 <- predict(tree, training)
tab1 <- table(Predicted = p1, Actual = training$Churn)
tab2 <- table(Predicted = pred_tree, Actual = testing$Churn)
print(paste('Decision Tree Accuracy',sum(diag(tab2))/sum(tab2)))

```

**The accuracy for Decision Tree has hardly improved. Let's see if we can do better using Random Forest.**

## **Random Forest**

### **Random Forest Initial Model**

```{r}
set.seed(2017)
rfModel <- randomForest(Churn ~., data = training)
print(rfModel)
```

The error rate is relatively low when predicting "No", and the error rate is much higher when predicting "Yes".

### **Random Forest Prediction and Confusion Matrix**

```{r}
pred_rf <- predict(rfModel, testing)
caret::confusionMatrix(pred_rf, testing$Churn)
```

### **Random Forest Error Rate**

```{r}
plot(rfModel)
```

We use this plot to help us determine the number of trees. As the number of trees increases, the OOB error rate decreases, and then becomes almost constant. We are not able to decrease the OOB error rate after about 100 to 200 trees.

### **Tune Random Forest Model**

```{r}
t <- tuneRF(training[, -18], training[, 18], stepFactor = 0.5, plot = TRUE, ntreeTry = 200, trace = TRUE, improve = 0.05)
```

We use this plot to give us some ideas on the number of mtry to choose. OOB error rate is at the lowest when mtry is 2. Therefore, we choose mtry=2.

### **Fit the Random Forest Model After Tuning**

```{r}
rfModel_new <- randomForest(Churn ~., data = training, ntree = 200, mtry = 2, importance = TRUE, proximity = TRUE)
print(rfModel_new)
```

OOB error rate decreased to 19.7% from 20.65% earlier.

### **Random Forest Predictions and Confusion Matrix After Tuning**

```{r}
pred_rf_new <- predict(rfModel_new, testing)
caret::confusionMatrix(pred_rf_new, testing$Churn)
```

The accuracy did not increase but the sensitivity improved, compare with the initial Random Forest model.

### **Random Forest Feature Importance**

```{r}
varImpPlot(rfModel_new, sort=T, n.var = 10, main = 'Top 10 Feature Importance')
```

## **Summary**

From the above example, we can see that Logistic Regression and Random Forest performed better than Decision Tree for customer churn analysis for this particular dataset.

Throughout the analysis, I have learned several important things:\
1. Features such as tenure_group, Contract, PaperlessBilling, MonthlyCharges and InternetService appear to play a role in customer churn.\
2. There does not seem to be a relationship between gender and churn.\
3. Customers in a month-to-month contract, with PaperlessBilling and are within 12 months tenure, are more likely to churn; On the other hand, customers with one or two year contract, with longer than 12 months tenure, that are not using PaperlessBilling, are less likely to churn.
